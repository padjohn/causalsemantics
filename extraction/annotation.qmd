---
title: "Annotation Guidelines"
subtitle: "How causal relations are annotated in the Causal Semantics framework"
---

## Overview

This page documents the annotation schema and guidelines used to produce the training data for [C-BERT](extraction/c-bert.qmd) and the underlying $(C, E, I)$ tuple representation. If you are using C-BERT or working with annotated data from this project, this page serves as the reference for how annotations are structured, what decisions were made, and how edge cases are handled.

The annotation was developed over three iterations (2024–2025) and primarily conducted via [INCEpTION](https://inception-project.github.io/). A total of 4,753 sentences from German environmental discourse (1990–2022) yielded 2,391 manually annotated causal relations.

## Annotation Schema

The schema consists of two layers: **span annotations** that mark causal components in text, and **relation annotations** that link them into structured causal relations.

### Spans

Each token or token sequence in a sentence receives at most one span label. There are two span categories.

**Role** marks the primary causal components:

- `Indicator` — the lexical marker that projects the causal relation 
  - e.g. *verursachen* 'cause', *ist Ursache* 'is cause', *weil* 'because', *stoppen* 'stop'
- `Entity` — a cause or effect entity involved in the relation 
  - e.g. *Klimawandel* 'climate change', *Pestizide* 'pesticides'

**Coefficient** captures semantic modifiers:

- `Negation` 
  - Neutralizes or inverts the causal relation 
  - *nicht* 'not', *kein* 'no', *Verlust* 'loss', *Schwund* 'shrinkage'
- `Division`
  - Lowers salience 
  - *auch* 'also', *unter anderem* 'among others'
- `Priority`
  - Increases salience
  - *vor allem* 'especially', *wichtig* 'important'

The three above directly affect influence. Other coefficients either run orthogonal (e.g. `temporality`) – or specify epistemic dimensions (e.g `Uncertainty`).

::: {.callout-note collapse="true"}

## Orthogonal coefficients

| Coefficient             | Function                  | Examples                                            |
| ----------------------- | ------------------------- | --------------------------------------------------- |
| `Temporality`           | Temporal framing          | *seit*, *bereits*, *künftig*, *Jahre*               |
| `Spatiality`            | Spatial framing           | *global*, *lokal*, *weltweit*, *Deutschland*        |
| `Quality`               | Qualitative modification  | *industrielle*, *parasitischer*, *schwefelhaltiger* |
| `Quantity`              | Quantitative modification | *großes*, *fünftausend*, *zwölf*                    |
: Object-based constraints

| Coefficient             | Function                  | Examples                                            |
| ----------------------- | ------------------------- | --------------------------------------------------- |
| `Uncertainty`           | Modality and hedging      | *möglicherweise*, *könnte*, *vermutlich*            |
| `Representation`        | Evidentiality marker      | *laut*, *sagt*, *sei*                               |
| `Representation Entity` | Source/provenance         | *Studie*, *Bericht*, *Forscher*                     |
: Propositional-based constraints
:::

### Relations

Annotated spans are linked by directed relations:

- `Cause`: Indicator → Entity (the entity is designated as a [Cause]{.smallcaps})
- `Effect`: Indicator → Entity (the entity fills the [Effect]{.smallcaps} role)
- `Constraint`: Entity or Indicator → Coefficient (the coefficient modifies its governor)

### Example

Consider the the spans in this sentence:

::: {layout-ncol="2"}

:::: {}

> [Klimawandel]{.entity} und [insbesondere]{.priority} [Landwirtschaft]{.entity} [verstärken]{.indicator} [möglicherweise]{.uncertainty} das [weltweite]{.spatiality} [Artensterben]{.entity}.

> [Climate change]{.entity} and [especially]{.priority} [agriculture]{.entity} [possibly]{.uncertainty} [intensify]{.indicator} [global]{.spatiality} [species extinction]{.entity}.



::::

:::: {}

Two coordinated entities (*Klimawandel und Landwirtschaft*) are annotated separately with parallel `Cause` relations.  
<br>
The adverb *insbesondere* 'especially' is scoped to *Landwirtschaft*, raising its salience as ``Priority``. The sentence adverb *möglicherweise* (`Uncertainty`) is parented to the indicator since it modifies the causal proposition.  
<br>
Lastly, the adjective *weltweit* is separately encoded as `Spatiality` coefficient – in accordance with the token minimization principle.

::::

:::


```{mermaid}
graph LR
    A["*verstärken*"] -->|Cause| B["*Klimawandel*"]
    A -->|Cause| C["*Landwirtschaft*"] -->|Priority| D["*insbesondere*"]
    A -->|Uncertainty| E["*möglicherweise*"]
    A -->|Effect| F["*Artensterben*"]
    F -->|Spatiality| G["*weltweit*"]
```


## Annotation Principles

Four principles guide annotation decisions in ambiguous cases.

### Minimal Principle

Only explicitly marked causal relations are annotated — no inference. When a lexically specific marker (e.g. *verursacht*) and a functional marker (e.g. *durch*) co-occur, only the lexically richer element is annotated as indicator. Functional prepositions and connectors are annotated as indicators only when no richer causal lexeme is present.

For light verb constructions, only the semantically loaded element is annotated (e.g. *hat etwas mit X **zu tun*** → Indicator: *tun*).

### Token Minimization

Entities are reduced to their head token. Attributive modifiers are extracted as separate coefficients:

- *industrielle Landwirtschaft* → Entity: `Landwirtschaft`, Coefficient: `industrielle` (Quality)
- *Einsatz von Pestiziden* → Entity: `Pestiziden`
- Exception: named entities (*Europäische Union*) and fixed multi-word expressions (*saurer Regen*) are annotated as single units.

This prevents proliferation of marginal entity variants and facilitates downstream aggregation.

### Syntactic Proximity

When multiple potential entities compete for a role, the syntactically closest entity to the indicator is preferred, unless semantic considerations override this.

### Coefficient Conservatism

Coefficients (other than `Representation`) are only annotated when they stand in a direct syntactic dependency relation with an indicator or entity.

## Indicators

Indicators are the lexical or syntactic markers that project causal relations and establish $(C, E, I)$ tuples. They fulfill two functions: projecting causal roles onto syntactic positions in their co-text, and encoding inherent information about polarity and salience.

The annotation corpus contains **642 distinct indicator forms**, grouped into **192 indicator families** by morphological and semantic criteria. A family subsumes all realizations of a shared lexical core. E.g. the [Ursache]{.smallcaps} family includes, among other:

- *verursachen* 'cause'
- *ist Ursache* 'is the cause', 
- *Ursache sein* 'to be the cause'
- *Teilursache sein* 'to be a partial cause'

### Top 10 Indicator Families

| Family                                                            | Forms | Instances |     | Family                | Forms | Instances |
| ----------------------------------------------------------------- | ----- | --------- | --- | --------------------- | ----- | --------- |
| [{{< g Ursache cause >}}]{.smallcaps} '[Cause]{.smallcaps}'       | 21    | 167       |     | [Beitrag]{.smallcaps} | 10    | 70        |
| [Verantwortung]{.smallcaps}  <br>  '[Responsibility]{.smallcaps}' | 11    | 122       |     | [Folge]{.smallcaps}   | 6     | 69        |
| [Stoppen]{.smallcaps}  <br>  '[Stop]{.smallcaps}'                 | 3     | 111       |     | [Kampf]{.smallcaps}   | 8     | 69        |
| [Gegen]{.smallcaps}  <br>  '[Against]{.smallcaps}'                | 3     | 95        |     | [Führen]{.smallcaps}  | 9     | 59        |
| [Durch]{.smallcaps}  <br> '[through]{.smallcaps}'                 | 2     | 70        |     | [Grund]{.smallcaps}   | 7     | 57        |

### Orientation
Some families are cause-oriented, others are effect-oriented. Compare:

> *Emission$_C$ is a cause of pollution$_E$.*  
> *Pollution$_E$ is an effect of emission$_C$.*

Alignment affects projection – cause-oriented indicators project [Cause]{.smallcaps} on the subject influence, effect-oriented indicators do the same with [Effect]{.smallcaps}. Predicates (*is the cause*), 

 as *Teilursache* 'partial cause' implies the existence of several causes – hence reducing it's salience. 'Teilwirkung' *partial effect*, on the other hand, implies a multitude of effects.  

### Polarity and Salience

Each indicator family carries a default **polarity** (promoting $+$ or inhibiting $-$) and a default **salience** class:

| Family                                                  | Polarity | Default Salience | Discourse Function                                                    |
| ------------------------------------------------------- | -------- | ---------------- | --------------------------------------------------------------------- |
| [Ursache]{.smallcaps} <br> '[Cause]{.smallcaps}'        | $+$      | $[0.5-1]$        | Prototype; full salience spectrum                                     |
| [Folge]{.smallcaps} <br> '[Consequence]{.smallcaps}'    | $+$      | $1$              | Effect-centered perspective                                           |
| [Beitrag]{.smallcaps} <br> '[Contribution]{.smallcaps}' | $+$      | $[0.5-0.75]$     | Distributional attribution                                            |
| [Durch]{.smallcaps} <br> '[Through]{.smallcaps}'        | $+$      | $1$              | Grammaticalized preposition                                           |
| [Stoppen]{.smallcaps} <br> '[Stop]{.smallcaps}'         | $−$      | $1$              | Intervention framing                                                  |
| [Gegen]{.smallcaps} <br> '[Against]{.smallcaps}'        | $−$      | $1$              | Variable condensation (*Kampf/Protest gegen* 'fight/protest against') |
| [Reduzieren]{.smallcaps}  <br>  '[Reduce]{.smallcaps}'  | $−$      | $[0.5-0.75]$     | Prototypical polycausal negative                                      |
| [Wirkung]{.smallcaps}  <br>  '[Effect]{.smallcaps}'     | $\pm$    | $[0-1]$          | Widest range                                                          |

Positive, though *Gegenwirkung* 'counter-effect' = $-$, *wirkungslos* 'ineffective' = 0

### Syntactic Projection Patterns

The syntactic realization of each indicator determines how [Cause]{.smallcaps} and [Effect]{.smallcaps} roles are projected:

| Family                                                    | Example                                          | Cause Projection     | Effect Projection     |
| --------------------------------------------------------- | ------------------------------------------------ | -------------------- | --------------------- |
| [Ursache]{.smallcaps} <br> '[Cause]{.smallcaps}'          | *X ist Ursache für Y*  <br> 'x is the cause of'  | Subject              | PP (*für*) <br> 'for' |
| [Folge]{.smallcaps} <br> '[Consequence]{.smallcaps}'      | *Y ist Folge von X* <br> 'x is a consequence of' | PP (*von*) <br> 'of' | Subject               |
| [Verursachen]{.smallcaps} <br> '[Cause]{.smallcaps}       | *X verursacht Y* <br> 'x causes y'               | Subject              | Accusative object     |
| [Beitragen]{.smallcaps} <br> '[Contribution]{.smallcaps}' | *X trägt zu Y bei* <br> 'x contributes to y'     | Subject              | PP (*zu*) <br> 'to'   |
| [Stoppen]{.smallcaps} <br> '[Stop]{.smallcaps}'           | *X stoppt Y* <br> 'x stops y'                    | Subject              | Accusative object     |
| [Durch]{.smallcaps} <br> '[Through]{.smallcaps}'          | *Y durch X*  <br> 'x through y'                  | PP complement        | Head noun             |
| [Gegen]{.smallcaps} <br> '[Against]{.smallcaps}'          | *X gegen Y* <br> 'x against y'                   | Subject              | PP complement         |

## Context Markers

Context markers modify and contextualize the causal relations projected by indicators. Unlike indicators, they are not lexically specialized for causality but operate at the predication or proposition level. Three structural marker types directly affect the INFLUENCE computation:

### Division

Division markers signal polycausal structures with implicit co-causes. Typical realizations include *unter anderem* ('among other things'), *auch* ('also'), *ebenfalls* ('likewise'), and the composite *nicht nur* ('not only').

Division markers reduce the salience to $|I| = 0.5$ regardless of the indicator's default.

### Priority

Priority markers establish asymmetric weighting within polycausal sets: *vor allem* ("above all"), *hauptsächlich* ('mainly), *maßgeblich* ('significantly'). They set $|I| = 0.75$ for the prioritized cause.

Both marker types affect only the salience ($|I|$), leaving polarity ($\pm$) unchanged.

### Negation

Negation is the structurally most influential marker. Two types are distinguished:

**Object-based negation** operates at the entity level through markers like *Verlust* ("loss"), *Schwund* ("decline"), *Rückgang* ("decrease"). These invert the polarity when the count of negations is odd:

> *Verlust von Lebensräumen verursacht Bienensterben.*
>
> Indicator *verursachen*: default $I > 0$; object negation on [Cause]{.smallcaps} (*Verlust*) → polarity inverted: $I < 0$.

**Propositional negation** operates at the relation level (*nicht*, *kein*) and neutralizes the entire causal relationship ($I = 0$):

> *Pestizide verursachen **nicht** Insektensterben.*
>
> Indicator *verursachen*: default $I > 0$; propositional negation → $I = 0$.

## From Annotations to INFLUENCE

The annotations documented above — indicators, entities, and context markers — are the inputs to a deterministic computation that produces the final INFLUENCE value $I \in [-1, +1]$. In brief: entity identification follows the indicator's syntactic projection pattern, polarity is determined by indicator class and negation markers, and salience is computed through a cascading hierarchy of morphological, determiner, and syntactic markers.

For the full formal specification — including the cascade rules, coordination normalization, and worked examples — see [Tuple Construction](../processing/tuple-construction.qmd).

## Data Format {#data-format}

Annotated data is exported as JSON. Each entry represents a sentence with its metadata and extracted relations.

### Schema

```json
{
  "subfolder": "Artensterben_oa",
  "global_sentence_id": 1148482,
  "text_id": "FAZ_200204_384209",
  "text_date": "2002-04",
  "sentence_id": "12",
  "sentence": "...",
  "relations": [
    {
      "indicator": "Folge",
      "entities": [
        {
          "entity": "Kleinplanet",
          "relation": "Cause",
          "dependent_coefficients": [
            {"coefficient_text": "Jahren", "coefficient": "Temporality"},
            {"coefficient_text": "Mexikos", "coefficient": "Spatiality"}
          ]
        },
        {
          "entity": "Artensterben",
          "relation": "Effect"
        }
      ],
      "coefficient": "Division",
      "dependent_coefficients": [
        {"coefficient_text": "könnte", "coefficient": "Uncertainty"}
      ],
      "representation": "berieten",
      "representation_entities": [
        {
          "entity": "Teilnehmer",
          "relation": "Constraint",
          "dependent_coefficients": [
            {"coefficient_text": "fünftausend", "coefficient": "Quantity"}
          ]
        }
      ]
    }
  ]
}
```

### Field Reference

**Sentence-level fields:**

| Field | Description |
|---|---|
| `subfolder` | WABI subcorpus and syntactic position (e.g. `Artensterben_oa` = accusative object) |
| `global_sentence_id` | Unique sentence identifier across the full corpus |
| `text_id` | Source document identifier (format: `SOURCE_YYYYMM_ID`) |
| `text_date` | Publication date (YYYY-MM) |
| `sentence` | Full sentence text |
| `relations` | Array of causal relations found in this sentence (empty if none) |

**Relation-level fields:**

| Field | Description |
|---|---|
| `indicator` | The causal indicator lexeme |
| `entities` | Array of entities with their causal role (`Cause` or `Effect`) |
| `coefficient` | Structural marker on the relation level (`Negation`, `Division`) |
| `dependent_coefficients` | Contextual coefficients attached to the indicator |
| `representation` | Evidentiality/speech-act verb (if present) |
| `representation_entities` | Source entities for reported speech |

**Entity-level fields:**

| Field | Description |
|---|---|
| `entity` | Head token of the entity (token-minimized) |
| `relation` | Causal role: `Cause`, `Effect`, or `Constraint` |
| `dependent_coefficients` | Array of coefficients modifying this entity |

### Sentences Without Relations

Sentences where no explicit causal relation was identified have an empty `relations` array. These are not noise — they were reviewed during annotation and determined to contain no explicit causal markers per the minimal principle.

## Corpus Statistics

| | |
|---|---|
| **Total sentences** | 4,753 |
| **Sentences with ≥1 WABI relation** | 1,797 (37.8%) |
| **Total WABI-relevant relations** | 1,867 |
| **Distinct indicator forms** | 642 |
| **Indicator families** | 192 |
| **Mean relations per sentence** | 0.39 |

**Per WABI term:**

| Term | Sentences | Relations | Rel./Sent. |
|---|---|---|---|
| Waldsterben | 1,818 | 633 | 0.35 |
| Artensterben | 1,854 | 744 | 0.40 |
| Bienensterben | 536 | 257 | 0.48 |
| Insektensterben | 545 | 233 | 0.43 |

## Further Reading

- For the theoretical motivation behind polarity and salience, see [Framework](framework/index.qmd)
- For how annotations are transformed into $(C, E, I)$ tuples, see [Tuple Construction](processing/tuple-construction.qmd)
- For the C-BERT model trained on this data, see [C-BERT](extraction/c-bert.qmd)
- Full annotation data (Bundestag subset): [HuggingFace Dataset](https://huggingface.co/datasets/pdjohn/bundestag-causal-attribution)
